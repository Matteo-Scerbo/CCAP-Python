{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Store data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a 1000 sample vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N=1000\n",
    "a=np.random.randn(N,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "with open('a_ntf.txt','w') as fp:\n",
    "    fp.write(str(a)) # we need to convert it as string!\n",
    "\n",
    "with open('a_ntf.txt','r') as fp:\n",
    "    a_ntf=fp.read() \n",
    "    \n",
    "print(type(a_ntf))\n",
    "a_ntf_parsed=np.array([float(a) for a in a_ntf.replace('[','').replace(']','').replace('\\n','  ').replace('  ',' ').split(' ') if a!=''])\n",
    "print(type(a_ntf_parsed))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little bit too complex, isn't it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "with open('a_pickle.pickle','wb') as fp:\n",
    "    pickle.dump(a,fp)\n",
    "with open('a_pickle.pickle','rb') as fp:\n",
    "    a_pickle=pickle.load(fp)\n",
    "    \n",
    "print(type(a_pickle))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already in the correct  data type!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "np.save('a_np.npy',a)\n",
    "a_np=np.load('a_np.npy')\n",
    "np.savez('a_npz.npz',a=a)\n",
    "data=np.load('a_npz.npz')\n",
    "a_npz=data['a']\n",
    "\n",
    "print(type(a_np))\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy to do, hard to read from external programs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "with open('a_json.json','w') as fp:\n",
    "    json.dump(a.tolist(),fp)\n",
    "    \n",
    "with open('a_json.json','r') as fp:\n",
    "    a_json=json.load(fp)\n",
    "    \n",
    "print(type(a_json))\n",
    "print(type(np.array(a_json)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison among types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error with Normal text file is 0.0000009436\n",
      "Error with pickle file is 0.0000000000\n",
      "Error with Numpy file is 0.0000000000\n",
      "Error with compressed  Numpy file is 0.0000000000\n",
      "Error with JSON file is 0.0000000000\n"
     ]
    }
   ],
   "source": [
    "print('Error with Normal text file is %.10f'%np.sum(np.abs(a_ntf_parsed-a)))\n",
    "print('Error with pickle file is %.10f'%np.sum(np.abs(a_pickle-a)))\n",
    "print('Error with Numpy file is %.10f'%np.sum(np.abs(a_np-a)))\n",
    "print('Error with compressed  Numpy file is %.10f'%np.sum(np.abs(a_npz-a)))\n",
    "print('Error with JSON file is %.10f'%np.sum(np.abs(np.array(a_json)-a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
